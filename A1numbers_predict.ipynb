{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neural network class definition\n",
    "import numpy\n",
    "import scipy.special           # scipy.special for the sigmoid function expit()\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "#data = pd.read_csv('E:/Experiment/Predict_Curve/exp1.csv')        \n",
    "\n",
    "    \n",
    "# neural network class definition\n",
    "class neuralNetwork:\n",
    "    # We try to create the normal codes rather than the specific codes, so that when we created a big nerual network, we just pass the \n",
    "    # parameters that we need.\n",
    "    \n",
    "    # initialise the neural network\n",
    "    def __init__(self,inputnodes, hiddenodes, outnodes, learningrate):\n",
    "        # set number of nodes in each input, hidden, output layer\n",
    "        self.inodes = inputnodes\n",
    "        self.hnodes = hiddenodes\n",
    "        self.onodes = outnodes\n",
    "        \n",
    "        # link weight matrices, wi_h and wh_o \n",
    "        # weigts inside the arrays are w_i_j, where link is from node i to j in the next layer\n",
    "        # wi_h means Winput_hidden\n",
    "        # wh_o means whidden_output\n",
    "        \n",
    "        #-0.5 means the range of weights is in the -0.5 to 0.5\n",
    "        #self.wi_h = (numpy.random.rand(self.hnodes, self.inodes)-0.5)\n",
    "        #self.wh_o = (numoy.random.rand(self.onodes, self.hnodes)-0.5)\n",
    "    \n",
    "        # the more complicate method to create weights\n",
    "        ### pow(self.inodes) and pow(self.hnodes) are different from the book(pow(self.hnodes),pow(self(onodes)))\n",
    "        self.wi_h = numpy.random.normal(0.0, pow(self.inodes,-0.5),(self.hnodes,self.inodes))\n",
    "        self.wh_o = numpy.random.normal(0.0, pow(self.hnodes,-0.5),(self.onodes,self.hnodes))\n",
    "        \n",
    "        # learning rate\n",
    "        self.lr = learningrate\n",
    "        \n",
    "        # activation function is the sigmoid function\n",
    "        self.activation_function = lambda x: scipy.special.expit(x)   # make self.activation_function be a activation function\n",
    "        pass\n",
    "    \n",
    "    # train the nerual network\n",
    "    def train(self,inputs_list,targets_list):\n",
    "     #The first part: computing the outputs by training examples\n",
    "        # convert inputs list to 2d array                                           \n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T\n",
    "        targets = numpy.array(targets_list, ndmin=2).T\n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wi_h, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.wh_o,hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        \n",
    "         # The second part: update the weights\n",
    "        # error is the (target - actual)\n",
    "        output_errors = targets - final_outputs\n",
    "        # hidden layer error is the output_errors, split by weights, recombined at hidden nodes\n",
    "        hidden_errors = numpy.dot(self.wh_o.T,output_errors)                         # matrix multiplication \n",
    "    \n",
    "        # update the weights for he links between the hidden and output layers\n",
    "        self.wh_o += self.lr * numpy.dot((output_errors*final_outputs * (1.0-final_outputs)), numpy.transpose(hidden_outputs))\n",
    "    \n",
    "        # update the weights for the links between the input and hidden layers\n",
    "        self.wi_h += self.lr * numpy.dot((hidden_errors*hidden_outputs*(1.0-hidden_outputs)),numpy.transpose(inputs))\n",
    "        pass\n",
    "    \n",
    "    # query the neural network\n",
    "    # accept the inputs and return the outputs\n",
    "    def query(self,inputs_list):\n",
    "        # convert inputs list to 2d array                           # we can use list,but it will consume more memory\n",
    "        inputs = numpy.array(inputs_list, ndmin=2).T                  # using array will avoid this condition and 2d array can tranpose \n",
    "        #inputss = numpy.array(inputs_list, ndmin=1)\n",
    "        #print(inputs_list)\n",
    "        #print(self.wi_h)\n",
    "        #print(inputs)\n",
    "        \n",
    "        \n",
    "        # calculate signals into hidden layer\n",
    "        hidden_inputs = numpy.dot(self.wi_h, inputs)\n",
    "        # calculate the signals emerging from hidden layer\n",
    "        hidden_outputs = self.activation_function(hidden_inputs)\n",
    "        \n",
    "        # calculate signals into final output layer\n",
    "        final_inputs = numpy.dot(self.wh_o,hidden_outputs)\n",
    "        # calculate the signals emerging from final output layer\n",
    "        final_outputs = self.activation_function(final_inputs)\n",
    "        return final_outputs\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of input, hidden and output nodes\n",
    "input_nodes = 7\n",
    "hidden_nodes = 6\n",
    "output_nodes = 7\n",
    "steps = 10000          # An estimate\n",
    "data_num = 2396\n",
    "i = 0\n",
    "j = 1\n",
    "\n",
    "# learning rate is 0.3\n",
    "learning_rate = 0.3\n",
    "\n",
    "# create instance of neural network\n",
    "n = neuralNetwork(input_nodes,hidden_nodes,output_nodes,learning_rate)\n",
    "\n",
    "# load training data\n",
    "data = pd.read_csv('E:/Experiment/Predict_Curve/exp4.csv')\n",
    "\n",
    "# train the data\n",
    "for j in range(steps):\n",
    "    i=0\n",
    "    for i in range(data_num-2):\n",
    "        input_data = data[i:i+1]\n",
    "        target_data = data[i+1:i+2]\n",
    "        n.train(input_data,target_data)\n",
    "        j += 1\n",
    "\n",
    "# predict the next data\n",
    "data_last = data[2395:2396]\n",
    "a = n.query(data_last)\n",
    "a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = n.query(data_last)\n",
    "b = a*32+1\n",
    "print(b)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       Issue  Red1     Red2   Red3    Red4   Red5     Red6  Blue balls\n",
      "2396  0.9588  0.25  0.34375  0.625  0.8125  0.875  0.90625       0.125\n",
      "       Issue     Red1     Red2     Red3     Red4     Red5     Red6  Blue balls\n",
      "0     0.0004  0.28125  0.31250  0.34375  0.37500  0.78125  0.84375     0.31250\n",
      "1     0.0008  0.09375  0.25000  0.56250  0.59375  0.62500  0.78125     0.34375\n",
      "2     0.0012  0.00000  0.18750  0.28125  0.68750  0.84375  0.96875     0.46875\n",
      "3     0.0016  0.09375  0.15625  0.18750  0.28125  0.37500  0.75000     0.06250\n",
      "4     0.0020  0.09375  0.15625  0.43750  0.50000  0.90625  0.93750     0.46875\n",
      "5     0.0024  0.00000  0.06250  0.28125  0.62500  0.78125  0.81250     0.15625\n",
      "6     0.0028  0.00000  0.25000  0.56250  0.62500  0.68750  0.78125     0.18750\n",
      "7     0.0032  0.12500  0.21875  0.25000  0.40625  0.50000  0.68750     0.21875\n",
      "8     0.0036  0.12500  0.25000  0.53125  0.59375  0.65625  0.90625     0.25000\n",
      "9     0.0040  0.00000  0.03125  0.21875  0.37500  0.50000  0.71875     0.37500\n",
      "10    0.0044  0.09375  0.12500  0.31250  0.34375  0.90625  0.96875     0.43750\n",
      "11    0.0048  0.03125  0.34375  0.46875  0.50000  0.81250  0.90625     0.34375\n",
      "12    0.0052  0.21875  0.37500  0.50000  0.62500  0.68750  0.96875     0.34375\n",
      "13    0.0056  0.06250  0.12500  0.18750  0.21875  0.62500  0.93750     0.03125\n",
      "14    0.0060  0.09375  0.31250  0.56250  0.75000  0.78125  0.96875     0.37500\n",
      "15    0.0064  0.31250  0.50000  0.84375  0.90625  0.93750  1.00000     0.15625\n",
      "16    0.0068  0.12500  0.21875  0.53125  0.68750  0.75000  0.93750     0.15625\n",
      "17    0.0072  0.12500  0.46875  0.56250  0.59375  0.75000  0.84375     0.37500\n",
      "18    0.0076  0.09375  0.21875  0.34375  0.37500  0.46875  1.00000     0.25000\n",
      "19    0.0080  0.18750  0.28125  0.75000  0.78125  0.81250  0.96875     0.09375\n",
      "20    0.0084  0.40625  0.43750  0.53125  0.75000  0.78125  0.90625     0.00000\n",
      "21    0.0088  0.03125  0.18750  0.31250  0.34375  0.40625  0.96875     0.21875\n",
      "22    0.0092  0.00000  0.28125  0.59375  0.65625  0.78125  0.93750     0.03125\n",
      "23    0.0096  0.03125  0.18750  0.43750  0.50000  0.65625  0.90625     0.40625\n",
      "24    0.0100  0.00000  0.12500  0.31250  0.37500  0.40625  0.81250     0.34375\n",
      "25    0.0104  0.21875  0.37500  0.43750  0.78125  0.87500  0.93750     0.46875\n",
      "26    0.0108  0.00000  0.31250  0.40625  0.50000  0.81250  0.84375     0.43750\n",
      "27    0.0112  0.15625  0.37500  0.46875  0.59375  0.84375  0.96875     0.18750\n",
      "28    0.0116  0.03125  0.18750  0.43750  0.78125  0.87500  0.96875     0.28125\n",
      "29    0.0120  0.03125  0.15625  0.37500  0.40625  0.68750  0.81250     0.18750\n",
      "...      ...      ...      ...      ...      ...      ...      ...         ...\n",
      "2367  0.9472  0.00000  0.18750  0.28125  0.65625  0.93750  0.96875     0.43750\n",
      "2368  0.9476  0.03125  0.09375  0.12500  0.21875  0.31250  0.90625     0.03125\n",
      "2369  0.9480  0.28125  0.37500  0.56250  0.62500  0.71875  0.90625     0.18750\n",
      "2370  0.9484  0.18750  0.28125  0.62500  0.68750  0.93750  1.00000     0.40625\n",
      "2371  0.9488  0.12500  0.18750  0.40625  0.46875  0.53125  0.62500     0.00000\n",
      "2372  0.9492  0.00000  0.03125  0.06250  0.40625  0.56250  1.00000     0.06250\n",
      "2373  0.9496  0.31250  0.43750  0.46875  0.59375  0.71875  0.93750     0.09375\n",
      "2374  0.9500  0.12500  0.18750  0.25000  0.31250  0.56250  0.75000     0.12500\n",
      "2375  0.9504  0.09375  0.12500  0.71875  0.84375  0.90625  1.00000     0.25000\n",
      "2376  0.9508  0.09375  0.31250  0.53125  0.56250  0.78125  0.96875     0.09375\n",
      "2377  0.9512  0.06250  0.31250  0.50000  0.53125  0.71875  0.75000     0.15625\n",
      "2378  0.9516  0.03125  0.34375  0.37500  0.68750  0.81250  0.84375     0.34375\n",
      "2379  0.9520  0.03125  0.12500  0.18750  0.21875  0.59375  0.81250     0.09375\n",
      "2380  0.9524  0.06250  0.18750  0.31250  0.62500  0.90625  1.00000     0.18750\n",
      "2381  0.9528  0.00000  0.28125  0.40625  0.43750  0.53125  0.93750     0.37500\n",
      "2382  0.9532  0.00000  0.21875  0.68750  0.75000  0.84375  0.87500     0.28125\n",
      "2383  0.9536  0.43750  0.46875  0.62500  0.81250  0.90625  1.00000     0.09375\n",
      "2384  0.9540  0.06250  0.37500  0.43750  0.56250  0.59375  0.81250     0.40625\n",
      "2385  0.9544  0.03125  0.15625  0.21875  0.28125  0.31250  0.50000     0.37500\n",
      "2386  0.9548  0.09375  0.56250  0.65625  0.78125  0.87500  0.90625     0.31250\n",
      "2387  0.9552  0.21875  0.31250  0.50000  0.68750  0.96875  1.00000     0.28125\n",
      "2388  0.9556  0.09375  0.12500  0.18750  0.28125  0.34375  0.65625     0.46875\n",
      "2389  0.9560  0.06250  0.37500  0.43750  0.53125  0.62500  1.00000     0.46875\n",
      "2390  0.9564  0.09375  0.21875  0.25000  0.37500  0.84375  1.00000     0.09375\n",
      "2391  0.9568  0.25000  0.43750  0.56250  0.62500  0.68750  0.87500     0.43750\n",
      "2392  0.9572  0.25000  0.31250  0.43750  0.65625  0.71875  0.78125     0.06250\n",
      "2393  0.9576  0.00000  0.12500  0.18750  0.25000  0.28125  0.59375     0.46875\n",
      "2394  0.9580  0.03125  0.28125  0.37500  0.46875  0.68750  0.96875     0.21875\n",
      "2395  0.9584  0.00000  0.18750  0.34375  0.40625  0.53125  0.75000     0.28125\n",
      "2396  0.9588  0.25000  0.34375  0.62500  0.81250  0.87500  0.90625     0.12500\n",
      "\n",
      "[2397 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy\n",
    "data = pd.read_csv('E:/Experiment/Predict_Curve/exp6.csv')\n",
    "#data_list = []\n",
    "data_list = data[2396:2397]\n",
    "print(data_list)\n",
    "\n",
    "#inputs = numpy.array(data_list, ndmin=2).T\n",
    "#inputs\n",
    "print(data)\n",
    "#data['Red1']\n",
    "#data[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.iloc[0,0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
